<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Learning Upright and Forward-Facing Object Poses using Category-level Canonical Representations">
  <!-- <meta name="keywords" content="Aligning with Human Preference,Point Cloud Canonicalization;"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GDG</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  
  <!-- 合并重复的head标签，将MathJax脚本移至此处 -->
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
     

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">GDG</h1>
          
          <!-- 作者和机构信息（保持注释状态，如需启用可移除注释） -->
          <!--<div class="is-size-5 publication-authors">
            <span class="author-block">Bing Han,</span>
            <span class="author-block">Ruitao Pan,</span>
            <span class="author-block">Xinyu Zhang,</span>
            <span class="author-block">Chenxi Wang,</span>
            <span class="author-block">Zhi Zhai,</span>
            <span class="author-block">Zhibin Zhao*,</span>
            <span class="author-block">Xuefeng Chen</span>
          </div>
          <div class="is-size-5 publication-affiliations">
            <span class="affiliation-block">Xi'an Jiaotong University</span>
          </div>-->
          
          <!-- 链接按钮（修复注释错误并闭合标签） -->
          <div class="publication-links">
            <!-- Code Link -->
            <!--<span class="link-block">
              <a href="https://github.com/anon-mity/upright_code" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code</span>
              </a>
            </span>-->
            
            <!-- Dataset Link（修复多余的注释闭合符） -->
            <span class="link-block">
              <a href="https://github.com/anon-mity/upright_code" class="external-link button is-normal is-rounded is-dark is-disabled" aria-disabled="true">
                <!-- 推荐使用禁用状态 -->
                <span class="icon"><i class="far fa-images"></i></span>
                <span>Data</span>
              </a>
            </span>
          </div> <!-- 闭合publication-links -->
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser-image" src="./static/images/img1.jpg" alt="Teaser image" height="100%">
      <p class="content has-text-justified">
        <strong>TL;DR:</strong> We propose a data-efficient, size-generalizable and physics-plausible method for dexterous grasp generation, which achieves State-Of-The-Art (SOTA) physical plausibility and competitive grasping performance with a relatively small number of parameters compared to previous SOTA methods.
      </p>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Achieving dexterous grasping remains a key challenge in robotics. Recent generative approaches enable diverse grasps through large-scale data-driven training, yet they often neglect geometric priors of objects, which leads to low data efficiency and poor physical plausibility. 
            We propose GeoDexGrasp, a geometry-aware generation framework for dexterous grasping built upon object-centric geometric representations. We introduce a SIM(3)-equivariant network equipped with a self-supervised disentanglement strategy to extract interpretable and transferable geometric features, including shape, size, pose, and interaction direction.
            The overall generation process is then decomposed into two stages: first, root rotation generation conditioned on pose and interaction direction; second, hand grasp generation guided by shape and size.
            By leveraging geometric representations, GeoDexGrasp achieves SOTA physical plausibility (reducing 40% penetration depth) across five datasets, and exhibits improved data efficiency. Additionally, GeoDexGrasp is also lightweight (using less than 20% of the parameters of the previous SOTA method) and attains a comparable grasp success rate.  
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Method</h2> <!-- 使用Bulma内置类替代内联样式 -->
    <div class="hero-body">
      <img id="method-image" src="./static/images/method.jpg" alt="Method architecture" height="100%"> <!-- 修复重复ID问题 -->
      <p class="content has-text-justified">
        <strong>Overall architecture.</strong> Pipeline of GeoDexGrasp. When the object undergoes pose, shape, or size variation, we expect the model to adapt its predictions accordingly rather than treating them as entirely new cases. GeoDexGrasp consists of three stages. <strong>Stage 1:</strong> Geometric representation learning and extraction. A SIM(3)-equivariant network is employed for self-supervised disentangled pretraining to obtain transferable geometric representations aligned with high-level semantics. <strong>Stage 2:</strong> Pose-guided rotation generation. Rotational distributions in SO(3) space are generated conditioned on pose representations and interaction directions. <strong>Stage 3:</strong> Shape-guided grasp generation. A diffusion model conditioned on object shape and size representations generates the final grasp in Euclidean space.
      </p>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Result</h2>
    <div class="hero-body">
      <img id="result-image" src="./static/images/dingxing.jpg" alt="Experimental results" height="100%">
      <p class="content has-text-justified"></p>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Data Efficiency</h2>
    <div class="hero-body">
      <img id="data-eff-image" src="./static/images/data_eff.jpg" alt="Data efficiency analysis" height="100%">
      <p class="content has-text-justified"></p>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Size Generalization</h2>
    <div class="hero-body">
      <img id="size-generalization-image" src="./static/images/shape.jpg" alt="Size generalization results" height="100%">
      <p class="content has-text-justified"></p>
    </div>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This webpage is modified based on the template provided by <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, and we thank them for their contributions.  
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
